{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -qqq transformers datasets evaluate","metadata":{"execution":{"iopub.status.busy":"2023-08-04T03:45:31.894174Z","iopub.execute_input":"2023-08-04T03:45:31.894678Z","iopub.status.idle":"2023-08-04T03:45:47.482485Z","shell.execute_reply.started":"2023-08-04T03:45:31.894641Z","shell.execute_reply":"2023-08-04T03:45:47.481121Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.simplefilter(\"ignore\")\nimport numpy as np \nimport pandas as pd \nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback\nfrom datasets import Dataset\nimport torch\nimport os\nos.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-04T03:45:47.486164Z","iopub.execute_input":"2023-08-04T03:45:47.486568Z","iopub.status.idle":"2023-08-04T03:46:02.300018Z","shell.execute_reply.started":"2023-08-04T03:45:47.486528Z","shell.execute_reply":"2023-08-04T03:46:02.299071Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data_path = '/kaggle/input/clickbait-detection-msci641-s23'","metadata":{"execution":{"iopub.status.busy":"2023-08-04T03:46:02.301594Z","iopub.execute_input":"2023-08-04T03:46:02.302377Z","iopub.status.idle":"2023-08-04T03:46:02.307808Z","shell.execute_reply.started":"2023-08-04T03:46:02.302341Z","shell.execute_reply":"2023-08-04T03:46:02.306881Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train = pd.read_json(f'{data_path}/train.jsonl', lines=True)\ntest = pd.read_json(f'{data_path}/test.jsonl', lines=True)\nval = pd.read_json(f'{data_path}/val.jsonl', lines=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T03:46:02.310455Z","iopub.execute_input":"2023-08-04T03:46:02.311431Z","iopub.status.idle":"2023-08-04T03:46:03.131349Z","shell.execute_reply.started":"2023-08-04T03:46:02.311396Z","shell.execute_reply":"2023-08-04T03:46:03.130320Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"microsoft/deberta-v3-large\")","metadata":{"execution":{"iopub.status.busy":"2023-08-04T03:46:03.132768Z","iopub.execute_input":"2023-08-04T03:46:03.133122Z","iopub.status.idle":"2023-08-04T03:46:04.968444Z","shell.execute_reply.started":"2023-08-04T03:46:03.133070Z","shell.execute_reply":"2023-08-04T03:46:04.967232Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92b10d796f8844de84df34b623a508b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/580 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da883356b9d0415cb447fc84aa7b5676"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac3b8f1bc8b04a3d968cefbe9a245382"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"def tokenize(examples):\n    return tokenizer(examples[\"text\"], truncation=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T03:46:04.969906Z","iopub.execute_input":"2023-08-04T03:46:04.970442Z","iopub.status.idle":"2023-08-04T03:46:04.976733Z","shell.execute_reply.started":"2023-08-04T03:46:04.970404Z","shell.execute_reply":"2023-08-04T03:46:04.975003Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"id2label = {0: 'passage', 1: 'phrase', 2: 'multi'}\nlabel2id = {'passage': 0, 'phrase': 1, 'multi': 2}","metadata":{"execution":{"iopub.status.busy":"2023-08-04T03:46:04.979079Z","iopub.execute_input":"2023-08-04T03:46:04.980232Z","iopub.status.idle":"2023-08-04T03:46:04.987799Z","shell.execute_reply.started":"2023-08-04T03:46:04.980178Z","shell.execute_reply":"2023-08-04T03:46:04.986666Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def preprocess_data(df, test=False):\n    ret = []\n    if test:\n        for _, i in df.iterrows():\n            platform = i['postPlatform']\n            post = ' '.join(i['postText'])\n            title = i['targetTitle']\n            description = i['targetDescription']\n            paragraph = ' '.join(i['targetParagraphs'])\n            keyword = i['targetKeywords']\n            text = f\"{platform} Post: {post} Website Title: {title} Website Description: {description} Website Paragraph: {paragraph} Website Keyword: {keyword}\"\n            ret += [{'text': text, 'id': i['id']}]\n            ret_df = pd.DataFrame(ret)\n        \n    else:\n        for _, i in df.iterrows():\n            platform = i['postPlatform']\n            post = ' '.join(i['postText'])\n            title = i['targetTitle']\n            description = i['targetDescription']\n            paragraph = ' '.join(i['targetParagraphs'])\n            keyword = i['targetKeywords']\n            text = f\"{platform} Post: {post} Website Title: {title} Website Description: {description} Website Paragraph: {paragraph} Website Keyword: {keyword}\"\n            ret += [{'text': text, 'labels': i['tags'][0]}]\n            ret_df = pd.DataFrame(ret)\n            ret_df['labels'] = ret_df['labels'].apply(lambda x: label2id[x])\n    \n    data = Dataset.from_pandas(ret_df)\n    tokenized_data = data.map(tokenize, batched=True)\n    return tokenized_data","metadata":{"execution":{"iopub.status.busy":"2023-08-04T03:46:04.989156Z","iopub.execute_input":"2023-08-04T03:46:04.989745Z","iopub.status.idle":"2023-08-04T03:46:05.001859Z","shell.execute_reply.started":"2023-08-04T03:46:04.989711Z","shell.execute_reply":"2023-08-04T03:46:05.000932Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_df = preprocess_data(train)\nval_df = preprocess_data(val)\ntest_df = preprocess_data(test, test=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T03:46:05.003254Z","iopub.execute_input":"2023-08-04T03:46:05.003807Z","iopub.status.idle":"2023-08-04T03:46:27.229219Z","shell.execute_reply.started":"2023-08-04T03:46:05.003769Z","shell.execute_reply":"2023-08-04T03:46:27.228158Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7d4ff0e7d0f46708103f4a317021d40"}},"metadata":{}},{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a4005024e3143ea9ad3249f26c16544"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e3d87979b3b4a6cab4807edc3066a04"}},"metadata":{}}]},{"cell_type":"code","source":"import evaluate\nf1 = evaluate.load(\"f1\", average='macro')\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return f1.compute(predictions=predictions, references=labels, average='macro')","metadata":{"execution":{"iopub.status.busy":"2023-08-04T03:46:27.233167Z","iopub.execute_input":"2023-08-04T03:46:27.234454Z","iopub.status.idle":"2023-08-04T03:46:29.454213Z","shell.execute_reply.started":"2023-08-04T03:46:27.234416Z","shell.execute_reply":"2023-08-04T03:46:29.453281Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.77k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"135e8812aee44a7482d658b41db6a521"}},"metadata":{}}]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    \"microsoft/deberta-v3-large\", num_labels=3, id2label=id2label, label2id=label2id\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T03:46:29.455610Z","iopub.execute_input":"2023-08-04T03:46:29.455945Z","iopub.status.idle":"2023-08-04T03:46:49.522569Z","shell.execute_reply.started":"2023-08-04T03:46:29.455912Z","shell.execute_reply":"2023-08-04T03:46:49.521672Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/874M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e8044c296e314a27ab43fba5aaaf033f"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2ForSequenceClassification: ['mask_predictions.classifier.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight']\n- This IS expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DebertaV2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.weight', 'classifier.bias', 'pooler.dense.weight', 'pooler.dense.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T03:46:49.523987Z","iopub.execute_input":"2023-08-04T03:46:49.524447Z","iopub.status.idle":"2023-08-04T03:46:49.530275Z","shell.execute_reply.started":"2023-08-04T03:46:49.524412Z","shell.execute_reply":"2023-08-04T03:46:49.528618Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"model\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=2,\n    gradient_accumulation_steps=4,\n    gradient_checkpointing=True,\n    fp16=True,\n    optim=\"adafactor\",\n    num_train_epochs=50,\n    warmup_ratio=0.1,\n    weight_decay=0.01,\n    logging_steps=5,\n    evaluation_strategy=\"steps\",\n    save_strategy=\"steps\",\n    load_best_model_at_end=True,\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T03:46:49.531917Z","iopub.execute_input":"2023-08-04T03:46:49.532754Z","iopub.status.idle":"2023-08-04T03:46:49.628670Z","shell.execute_reply.started":"2023-08-04T03:46:49.532609Z","shell.execute_reply":"2023-08-04T03:46:49.627638Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_df,\n    eval_dataset=val_df,\n    callbacks = [EarlyStoppingCallback(early_stopping_patience=5)],\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T03:46:49.629942Z","iopub.execute_input":"2023-08-04T03:46:49.630841Z","iopub.status.idle":"2023-08-04T03:46:55.115015Z","shell.execute_reply.started":"2023-08-04T03:46:49.630800Z","shell.execute_reply":"2023-08-04T03:46:55.113767Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-08-04T03:46:55.116787Z","iopub.execute_input":"2023-08-04T03:46:55.117188Z","iopub.status.idle":"2023-08-04T03:51:22.259776Z","shell.execute_reply.started":"2023-08-04T03:46:55.117150Z","shell.execute_reply":"2023-08-04T03:51:22.258135Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [    6/20000 03:11 < 265:46:12, 0.02 it/s, Epoch 0.01/50]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>\n    <div>\n      \n      <progress value='11' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [ 11/100 00:11 < 01:44, 0.85 it/s]\n    </div>\n    "},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 trainer.train()                                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m1645\u001b[0m in \u001b[92mtrain\u001b[0m                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1642 \u001b[0m\u001b[2m│   │   \u001b[0minner_training_loop = find_executable_batch_size(                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1643 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._inner_training_loop, \u001b[96mself\u001b[0m._train_batch_size, args.auto_find_batch_size  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1644 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1645 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m inner_training_loop(                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1646 \u001b[0m\u001b[2m│   │   │   \u001b[0margs=args,                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1647 \u001b[0m\u001b[2m│   │   │   \u001b[0mresume_from_checkpoint=resume_from_checkpoint,                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1648 \u001b[0m\u001b[2m│   │   │   \u001b[0mtrial=trial,                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m2020\u001b[0m in \u001b[92m_inner_training_loop\u001b[0m     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2017 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.state.epoch = epoch + (step + \u001b[94m1\u001b[0m + steps_skipped) / steps_in_epo  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2018 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.control = \u001b[96mself\u001b[0m.callback_handler.on_step_end(args, \u001b[96mself\u001b[0m.state, \u001b[96ms\u001b[0m  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2019 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2020 \u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_k  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2021 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2022 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.control = \u001b[96mself\u001b[0m.callback_handler.on_substep_end(args, \u001b[96mself\u001b[0m.state  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2023 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m2321\u001b[0m in \u001b[92m_maybe_log_save_evaluate\u001b[0m \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2318 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m)                                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2319 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mmetrics.update(dataset_metrics)                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2320 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2321 \u001b[2m│   │   │   │   \u001b[0mmetrics = \u001b[96mself\u001b[0m.evaluate(ignore_keys=ignore_keys_for_eval)                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2322 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m._report_to_hp_search(trial, \u001b[96mself\u001b[0m.state.global_step, metrics)             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2323 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2324 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Run delayed LR scheduler now that metrics are populated\u001b[0m                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m3053\u001b[0m in \u001b[92mevaluate\u001b[0m                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3050 \u001b[0m\u001b[2m│   │   \u001b[0mstart_time = time.time()                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3051 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3052 \u001b[0m\u001b[2m│   │   \u001b[0meval_loop = \u001b[96mself\u001b[0m.prediction_loop \u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.args.use_legacy_prediction_loop \u001b[94melse\u001b[0m \u001b[96mse\u001b[0m  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3053 \u001b[2m│   │   \u001b[0moutput = eval_loop(                                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3054 \u001b[0m\u001b[2m│   │   │   \u001b[0meval_dataloader,                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3055 \u001b[0m\u001b[2m│   │   │   \u001b[0mdescription=\u001b[33m\"\u001b[0m\u001b[33mEvaluation\u001b[0m\u001b[33m\"\u001b[0m,                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3056 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# No point gathering the predictions if there are no metrics, otherwise we d\u001b[0m  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m3245\u001b[0m in \u001b[92mevaluation_loop\u001b[0m          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3242 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mbatch_size = observed_batch_size                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3243 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3244 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# Prediction step\u001b[0m                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3245 \u001b[2m│   │   │   \u001b[0mloss, logits, labels = \u001b[96mself\u001b[0m.prediction_step(model, inputs, prediction_loss_o  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3246 \u001b[0m\u001b[2m│   │   │   \u001b[0minputs_decode = \u001b[96mself\u001b[0m._prepare_input(inputs[\u001b[33m\"\u001b[0m\u001b[33minput_ids\u001b[0m\u001b[33m\"\u001b[0m]) \u001b[94mif\u001b[0m args.include_inp  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3247 \u001b[0m\u001b[2m│   │   │   \u001b[0m                                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3248 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m is_torch_tpu_available():                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m3503\u001b[0m in \u001b[92mprediction_step\u001b[0m          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3500 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3501 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m has_labels \u001b[95mor\u001b[0m loss_without_labels:                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3502 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mwith\u001b[0m \u001b[96mself\u001b[0m.compute_loss_context_manager():                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3503 \u001b[2m│   │   │   │   │   │   \u001b[0mloss, outputs = \u001b[96mself\u001b[0m.compute_loss(model, inputs, return_outputs=  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3504 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mloss = loss.mean().detach()                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3505 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m                                                                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m3506 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(outputs, \u001b[96mdict\u001b[0m):                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/transformers/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m2784\u001b[0m in \u001b[92mcompute_loss\u001b[0m             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2781 \u001b[0m\u001b[2m│   │   │   \u001b[0mlabels = inputs.pop(\u001b[33m\"\u001b[0m\u001b[33mlabels\u001b[0m\u001b[33m\"\u001b[0m)                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2782 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2783 \u001b[0m\u001b[2m│   │   │   \u001b[0mlabels = \u001b[94mNone\u001b[0m                                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2784 \u001b[2m│   │   \u001b[0moutputs = model(**inputs)                                                         \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2785 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Save past state if it exists\u001b[0m                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2786 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# TODO: this needs to be fixed and made cleaner later.\u001b[0m                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m2787 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.args.past_index >= \u001b[94m0\u001b[0m:                                                     \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._forward_hooks   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hooks                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks):                   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []                             \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/\u001b[0m\u001b[1;33mdata_parallel.py\u001b[0m:\u001b[94m171\u001b[0m in \u001b[92mforward\u001b[0m        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m168 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mlen\u001b[0m(\u001b[96mself\u001b[0m.device_ids) == \u001b[94m1\u001b[0m:                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m169 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.module(*inputs[\u001b[94m0\u001b[0m], **kwargs[\u001b[94m0\u001b[0m])                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m170 \u001b[0m\u001b[2m│   │   │   \u001b[0mreplicas = \u001b[96mself\u001b[0m.replicate(\u001b[96mself\u001b[0m.module, \u001b[96mself\u001b[0m.device_ids[:\u001b[96mlen\u001b[0m(inputs)])          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m171 \u001b[2m│   │   │   \u001b[0moutputs = \u001b[96mself\u001b[0m.parallel_apply(replicas, inputs, kwargs)                        \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m172 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.gather(outputs, \u001b[96mself\u001b[0m.output_device)                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m173 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m174 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mreplicate\u001b[0m(\u001b[96mself\u001b[0m, module, device_ids):                                               \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/\u001b[0m\u001b[1;33mdata_parallel.py\u001b[0m:\u001b[94m181\u001b[0m in \u001b[92mparallel_apply\u001b[0m \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m178 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m scatter_kwargs(inputs, kwargs, device_ids, dim=\u001b[96mself\u001b[0m.dim)                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m179 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m180 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mparallel_apply\u001b[0m(\u001b[96mself\u001b[0m, replicas, inputs, kwargs):                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m181 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m parallel_apply(replicas, inputs, kwargs, \u001b[96mself\u001b[0m.device_ids[:\u001b[96mlen\u001b[0m(replicas)])   \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m182 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m183 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mgather\u001b[0m(\u001b[96mself\u001b[0m, outputs, output_device):                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m184 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m gather(outputs, output_device, dim=\u001b[96mself\u001b[0m.dim)                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/\u001b[0m\u001b[1;33mparallel_apply.py\u001b[0m:\u001b[94m89\u001b[0m in \u001b[92mparallel_apply\u001b[0m \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m86 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfor\u001b[0m i \u001b[95min\u001b[0m \u001b[96mrange\u001b[0m(\u001b[96mlen\u001b[0m(inputs)):                                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m87 \u001b[0m\u001b[2m│   │   \u001b[0moutput = results[i]                                                                 \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m88 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96misinstance\u001b[0m(output, ExceptionWrapper):                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m89 \u001b[2m│   │   │   \u001b[0moutput.reraise()                                                                \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m90 \u001b[0m\u001b[2m│   │   \u001b[0moutputs.append(output)                                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m91 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m outputs                                                                          \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m92 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/\u001b[0m\u001b[1;33m_utils.py\u001b[0m:\u001b[94m644\u001b[0m in \u001b[92mreraise\u001b[0m                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m641 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# If the exception takes multiple arguments, don't try to\u001b[0m                      \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m642 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# instantiate since we don't know how to\u001b[0m                                       \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m643 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mRuntimeError\u001b[0m(msg) \u001b[94mfrom\u001b[0m \u001b[94mNone\u001b[0m                                              \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m644 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m exception                                                                    \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m645 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m646 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n\u001b[31m│\u001b[0m   \u001b[2m647 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_get_available_device_type\u001b[0m():                                                          \u001b[31m│\u001b[0m\n\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n\u001b[1;91mOutOfMemoryError: \u001b[0mCaught OutOfMemoryError in replica \u001b[1;36m0\u001b[0m on device \u001b[1;36m0\u001b[0m.\nOriginal Traceback \u001b[1m(\u001b[0mmost recent call last\u001b[1m)\u001b[0m:\n  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\"\u001b[0m, line \u001b[1;36m64\u001b[0m, in _worker\n    output = \u001b[1;35mmodule\u001b[0m\u001b[1m(\u001b[0m*input, **kwargs\u001b[1m)\u001b[0m\n  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[1;36m1501\u001b[0m, in _call_impl\n    return \u001b[1;35mforward_call\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m\n  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\"\u001b[0m, line \u001b[1;36m1310\u001b[0m, \nin forward\n    outputs = \u001b[1;35mself.deberta\u001b[0m\u001b[1m(\u001b[0m\n  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[1;36m1501\u001b[0m, in _call_impl\n    return \u001b[1;35mforward_call\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m\n  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\"\u001b[0m, line \u001b[1;36m1082\u001b[0m, \nin forward\n    encoder_outputs = \u001b[1;35mself.encoder\u001b[0m\u001b[1m(\u001b[0m\n  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[1;36m1501\u001b[0m, in _call_impl\n    return \u001b[1;35mforward_call\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m\n  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\"\u001b[0m, line \u001b[1;36m520\u001b[0m, \nin forward\n    output_states = \u001b[1;35mlayer_module\u001b[0m\u001b[1m(\u001b[0m\n  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[1;36m1501\u001b[0m, in _call_impl\n    return \u001b[1;35mforward_call\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m\n  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\"\u001b[0m, line \u001b[1;36m362\u001b[0m, \nin forward\n    attention_output = \u001b[1;35mself.attention\u001b[0m\u001b[1m(\u001b[0m\n  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[1;36m1501\u001b[0m, in _call_impl\n    return \u001b[1;35mforward_call\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m\n  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\"\u001b[0m, line \u001b[1;36m293\u001b[0m, \nin forward\n    self_output = \u001b[1;35mself.self\u001b[0m\u001b[1m(\u001b[0m\n  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[1;36m1501\u001b[0m, in _call_impl\n    return \u001b[1;35mforward_call\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m\n  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\"\u001b[0m, line \u001b[1;36m727\u001b[0m, \nin forward\n    rel_att = \u001b[1;35mself.disentangled_attention_bias\u001b[0m\u001b[1m(\u001b[0m\n  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\"\u001b[0m, line \u001b[1;36m810\u001b[0m, \nin disentangled_attention_bias\n    score += c2p_att \u001b[35m/\u001b[0m \u001b[1;35mscale.to\u001b[0m\u001b[1m(\u001b[0m\u001b[33mdtype\u001b[0m=\u001b[35mc2p_att\u001b[0m.dtype\u001b[1m)\u001b[0m\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate \u001b[1;36m3.00\u001b[0m GiB \u001b[1m(\u001b[0mGPU \u001b[1;36m0\u001b[0m; \u001b[1;36m14.76\u001b[0m GiB total capacity; \u001b[1;36m11.56\u001b[0m\nGiB already allocated; \u001b[1;36m947.75\u001b[0m MiB free; \u001b[1;36m12.83\u001b[0m GiB reserved in total by PyTorch\u001b[1m)\u001b[0m If reserved memory is >> allocated \nmemory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \nPYTORCH_CUDA_ALLOC_CONF\n\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 trainer.train()                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1645</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">train</span>                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1642 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>inner_training_loop = find_executable_batch_size(                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1643 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._inner_training_loop, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._train_batch_size, args.auto_find_batch_size  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1644 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1645 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> inner_training_loop(                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1646 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>args=args,                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1647 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>resume_from_checkpoint=resume_from_checkpoint,                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1648 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>trial=trial,                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2020</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_inner_training_loop</span>     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2017 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state.epoch = epoch + (step + <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span> + steps_skipped) / steps_in_epo  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2018 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.control = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.callback_handler.on_step_end(args, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">s</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2019 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2020 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_k  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2021 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2022 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.control = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.callback_handler.on_substep_end(args, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2023 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2321</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_maybe_log_save_evaluate</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2318 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>)                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2319 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>metrics.update(dataset_metrics)                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2320 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2321 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>metrics = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.evaluate(ignore_keys=ignore_keys_for_eval)                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2322 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._report_to_hp_search(trial, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state.global_step, metrics)             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2323 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2324 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Run delayed LR scheduler now that metrics are populated</span>                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3053</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">evaluate</span>                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3050 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>start_time = time.time()                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3051 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3052 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>eval_loop = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.prediction_loop <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.args.use_legacy_prediction_loop <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">se</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3053 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>output = eval_loop(                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3054 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>eval_dataloader,                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3055 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>description=<span style=\"color: #808000; text-decoration-color: #808000\">\"Evaluation\"</span>,                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3056 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># No point gathering the predictions if there are no metrics, otherwise we d</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3245</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">evaluation_loop</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3242 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>batch_size = observed_batch_size                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3243 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3244 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Prediction step</span>                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3245 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>loss, logits, labels = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.prediction_step(model, inputs, prediction_loss_o  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3246 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>inputs_decode = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._prepare_input(inputs[<span style=\"color: #808000; text-decoration-color: #808000\">\"input_ids\"</span>]) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> args.include_inp  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3247 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3248 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> is_torch_tpu_available():                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3503</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">prediction_step</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3501 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> has_labels <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> loss_without_labels:                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.compute_loss_context_manager():                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3503 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   </span>loss, outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.compute_loss(model, inputs, return_outputs=  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>loss = loss.mean().detach()                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3505 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span>                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3506 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(outputs, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">dict</span>):                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2784</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_loss</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2781 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>labels = inputs.pop(<span style=\"color: #808000; text-decoration-color: #808000\">\"labels\"</span>)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2782 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2783 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>labels = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2784 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>outputs = model(**inputs)                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2785 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Save past state if it exists</span>                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2786 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># TODO: this needs to be fixed and made cleaner later.</span>                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2787 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.args.past_index &gt;= <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>:                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1501</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_impl</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1498 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> (<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._forward_hooks   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1499 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_pre_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_backward_hooks                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1500 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_hooks <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> _global_forward_pre_hooks):                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1501 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> forward_call(*args, **kwargs)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1502 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Do not call functions when jit is used</span>                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1503 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>full_backward_hooks, non_full_backward_hooks = [], []                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1504 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>backward_pre_hooks = []                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">data_parallel.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">171</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">forward</span>        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">168 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.device_ids) == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>:                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">169 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.module(*inputs[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>], **kwargs[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>])                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">170 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>replicas = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.replicate(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.module, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.device_ids[:<span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(inputs)])          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>171 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>outputs = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.parallel_apply(replicas, inputs, kwargs)                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">172 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.gather(outputs, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.output_device)                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">173 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">174 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">replicate</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, module, device_ids):                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">data_parallel.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">181</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">parallel_apply</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">178 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> scatter_kwargs(inputs, kwargs, device_ids, dim=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dim)                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">179 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">180 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">parallel_apply</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, replicas, inputs, kwargs):                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>181 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> parallel_apply(replicas, inputs, kwargs, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.device_ids[:<span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(replicas)])   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">182 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">183 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">gather</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, outputs, output_device):                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">184 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> gather(outputs, output_device, dim=<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.dim)                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">parallel_apply.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">89</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">parallel_apply</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">86 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> i <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">range</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">len</span>(inputs)):                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">87 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>output = results[i]                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">88 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">isinstance</span>(output, ExceptionWrapper):                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>89 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>output.reraise()                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">90 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>outputs.append(output)                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">91 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> outputs                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">92 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">644</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">reraise</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">641 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># If the exception takes multiple arguments, don't try to</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">642 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># instantiate since we don't know how to</span>                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">643 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">RuntimeError</span>(msg) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>644 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> exception                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">645 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">646 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">647 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_get_available_device_type</span>():                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OutOfMemoryError: </span>Caught OutOfMemoryError in replica <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span> on device <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>.\nOriginal Traceback <span style=\"font-weight: bold\">(</span>most recent call last<span style=\"font-weight: bold\">)</span>:\n  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">64</span>, in _worker\n    output = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">module</span><span style=\"font-weight: bold\">(</span>*input, **kwargs<span style=\"font-weight: bold\">)</span>\n  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1501</span>, in _call_impl\n    return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">forward_call</span><span style=\"font-weight: bold\">(</span>*args, **kwargs<span style=\"font-weight: bold\">)</span>\n  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1310</span>, \nin forward\n    outputs = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.deberta</span><span style=\"font-weight: bold\">(</span>\n  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1501</span>, in _call_impl\n    return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">forward_call</span><span style=\"font-weight: bold\">(</span>*args, **kwargs<span style=\"font-weight: bold\">)</span>\n  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1082</span>, \nin forward\n    encoder_outputs = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.encoder</span><span style=\"font-weight: bold\">(</span>\n  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1501</span>, in _call_impl\n    return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">forward_call</span><span style=\"font-weight: bold\">(</span>*args, **kwargs<span style=\"font-weight: bold\">)</span>\n  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">520</span>, \nin forward\n    output_states = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">layer_module</span><span style=\"font-weight: bold\">(</span>\n  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1501</span>, in _call_impl\n    return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">forward_call</span><span style=\"font-weight: bold\">(</span>*args, **kwargs<span style=\"font-weight: bold\">)</span>\n  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">362</span>, \nin forward\n    attention_output = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.attention</span><span style=\"font-weight: bold\">(</span>\n  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1501</span>, in _call_impl\n    return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">forward_call</span><span style=\"font-weight: bold\">(</span>*args, **kwargs<span style=\"font-weight: bold\">)</span>\n  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">293</span>, \nin forward\n    self_output = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.self</span><span style=\"font-weight: bold\">(</span>\n  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1501</span>, in _call_impl\n    return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">forward_call</span><span style=\"font-weight: bold\">(</span>*args, **kwargs<span style=\"font-weight: bold\">)</span>\n  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">727</span>, \nin forward\n    rel_att = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.disentangled_attention_bias</span><span style=\"font-weight: bold\">(</span>\n  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">810</span>, \nin disentangled_attention_bias\n    score += c2p_att <span style=\"color: #800080; text-decoration-color: #800080\">/</span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">scale.to</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">c2p_att</span>.dtype<span style=\"font-weight: bold\">)</span>\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.00</span> GiB <span style=\"font-weight: bold\">(</span>GPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.76</span> GiB total capacity; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11.56</span>\nGiB already allocated; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">947.75</span> MiB free; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12.83</span> GiB reserved in total by PyTorch<span style=\"font-weight: bold\">)</span> If reserved memory is &gt;&gt; allocated \nmemory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \nPYTORCH_CUDA_ALLOC_CONF\n\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"pred = trainer.predict(test_df).predictions\npred_ids = np.argmax(pred, 1)\ntest['spoilerType'] = pred_ids\ntest['spoilerType'] = test['spoilerType'].apply(lambda x: id2label[x])\nsubmissions = test[['id', 'spoilerType']]","metadata":{"execution":{"iopub.status.busy":"2023-08-04T03:51:22.260758Z","iopub.status.idle":"2023-08-04T03:51:22.261278Z","shell.execute_reply.started":"2023-08-04T03:51:22.260991Z","shell.execute_reply":"2023-08-04T03:51:22.261026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submissions.to_csv('submissions.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-04T03:51:22.263672Z","iopub.status.idle":"2023-08-04T03:51:22.264209Z","shell.execute_reply.started":"2023-08-04T03:51:22.263916Z","shell.execute_reply":"2023-08-04T03:51:22.263940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}