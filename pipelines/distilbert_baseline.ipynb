{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -qqq transformers datasets evaluate","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:30:49.111855Z","iopub.execute_input":"2023-08-03T16:30:49.112222Z","iopub.status.idle":"2023-08-03T16:31:03.453032Z","shell.execute_reply.started":"2023-08-03T16:30:49.112190Z","shell.execute_reply":"2023-08-03T16:31:03.451457Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.simplefilter(\"ignore\")\nimport numpy as np \nimport pandas as pd \nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\nfrom datasets import Dataset","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-03T16:31:03.457101Z","iopub.execute_input":"2023-08-03T16:31:03.458162Z","iopub.status.idle":"2023-08-03T16:31:16.431060Z","shell.execute_reply.started":"2023-08-03T16:31:03.458125Z","shell.execute_reply":"2023-08-03T16:31:16.429979Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"data_path = '/kaggle/input/clickbait-detection-msci641-s23'","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:31:16.432301Z","iopub.execute_input":"2023-08-03T16:31:16.433606Z","iopub.status.idle":"2023-08-03T16:31:16.438765Z","shell.execute_reply.started":"2023-08-03T16:31:16.433566Z","shell.execute_reply":"2023-08-03T16:31:16.437627Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train = pd.read_json(f'{data_path}/train.jsonl', lines=True)\ntest = pd.read_json(f'{data_path}/test.jsonl', lines=True)\nval = pd.read_json(f'{data_path}/val.jsonl', lines=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:31:16.441685Z","iopub.execute_input":"2023-08-03T16:31:16.442052Z","iopub.status.idle":"2023-08-03T16:31:17.073966Z","shell.execute_reply.started":"2023-08-03T16:31:16.442011Z","shell.execute_reply":"2023-08-03T16:31:17.072955Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:31:17.075143Z","iopub.execute_input":"2023-08-03T16:31:17.075487Z","iopub.status.idle":"2023-08-03T16:31:19.517955Z","shell.execute_reply.started":"2023-08-03T16:31:17.075457Z","shell.execute_reply":"2023-08-03T16:31:19.516947Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16fa99bed8a148d3a6fba025df9c1b88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7850cc1addb540229d7d86780a511b2f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4649005f8f646d7a534fcf0ef199eeb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b66803937d4421ab94b7f5bbeb2da3c"}},"metadata":{}}]},{"cell_type":"code","source":"def tokenize(examples):\n    return tokenizer(examples[\"text\"], truncation=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:31:19.519483Z","iopub.execute_input":"2023-08-03T16:31:19.520488Z","iopub.status.idle":"2023-08-03T16:31:19.525661Z","shell.execute_reply.started":"2023-08-03T16:31:19.520453Z","shell.execute_reply":"2023-08-03T16:31:19.524525Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"id2label = {0: 'passage', 1: 'phrase', 2: 'multi'}\nlabel2id = {'passage': 0, 'phrase': 1, 'multi': 2}","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:31:19.527163Z","iopub.execute_input":"2023-08-03T16:31:19.527541Z","iopub.status.idle":"2023-08-03T16:31:19.536361Z","shell.execute_reply.started":"2023-08-03T16:31:19.527504Z","shell.execute_reply":"2023-08-03T16:31:19.535061Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def preprocess_data(df, test=False):\n    ret = []\n    if test:\n        for _, i in df.iterrows():\n            ret += [{'text': ' '.join(i['postText']) + ' - ' + i['targetTitle'] + ' ' + ' '.join(i['targetParagraphs']), 'id': i['id']}]\n            ret_df = pd.DataFrame(ret)\n        \n    else:\n        for _, i in df.iterrows():\n            ret += [{'text': ' '.join(i['postText']) + ' - ' + i['targetTitle'] + ' ' + ' '.join(i['targetParagraphs']), 'labels': i['tags'][0]}]\n            ret_df = pd.DataFrame(ret)\n            ret_df['labels'] = ret_df['labels'].apply(lambda x: label2id[x])\n    \n    data = Dataset.from_pandas(ret_df)\n    tokenized_data = data.map(tokenize, batched=True)\n    return tokenized_data","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:31:19.537817Z","iopub.execute_input":"2023-08-03T16:31:19.538554Z","iopub.status.idle":"2023-08-03T16:31:19.548289Z","shell.execute_reply.started":"2023-08-03T16:31:19.538521Z","shell.execute_reply":"2023-08-03T16:31:19.547263Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_df = preprocess_data(train)\nval_df = preprocess_data(val)\ntest_df = preprocess_data(test, test=True)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:31:19.549615Z","iopub.execute_input":"2023-08-03T16:31:19.549978Z","iopub.status.idle":"2023-08-03T16:31:37.773197Z","shell.execute_reply.started":"2023-08-03T16:31:19.549946Z","shell.execute_reply":"2023-08-03T16:31:37.772030Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86a829fd483141e4bc48814ab7e8f458"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67453dccb4d94b8086a11655a58a4d82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"727a99d0b4c94661bad25eb82431c520"}},"metadata":{}}]},{"cell_type":"code","source":"import evaluate\naccuracy = evaluate.load(\"accuracy\")\n\ndef compute_metrics(eval_pred):\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n    return accuracy.compute(predictions=predictions, references=labels)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:31:37.776978Z","iopub.execute_input":"2023-08-03T16:31:37.777652Z","iopub.status.idle":"2023-08-03T16:31:40.858686Z","shell.execute_reply.started":"2023-08-03T16:31:37.777616Z","shell.execute_reply":"2023-08-03T16:31:40.857805Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c646c71c56a14abab2f8ff5cc4b10b49"}},"metadata":{}}]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(\n    \"distilbert-base-uncased\", num_labels=3, id2label=id2label, label2id=label2id\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:31:40.859966Z","iopub.execute_input":"2023-08-03T16:31:40.860414Z","iopub.status.idle":"2023-08-03T16:31:51.939756Z","shell.execute_reply.started":"2023-08-03T16:31:40.860381Z","shell.execute_reply":"2023-08-03T16:31:51.938853Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6bed31a02750495984b0bc0e240fd867"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight']\n- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:31:51.941300Z","iopub.execute_input":"2023-08-03T16:31:51.941841Z","iopub.status.idle":"2023-08-03T16:31:51.947175Z","shell.execute_reply.started":"2023-08-03T16:31:51.941804Z","shell.execute_reply":"2023-08-03T16:31:51.946071Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"model\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=2,\n    weight_decay=0.01,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:31:51.948884Z","iopub.execute_input":"2023-08-03T16:31:51.949318Z","iopub.status.idle":"2023-08-03T16:31:51.997749Z","shell.execute_reply.started":"2023-08-03T16:31:51.949286Z","shell.execute_reply":"2023-08-03T16:31:51.996813Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_df,\n    eval_dataset=val_df,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:31:51.999204Z","iopub.execute_input":"2023-08-03T16:31:51.999540Z","iopub.status.idle":"2023-08-03T16:31:56.803351Z","shell.execute_reply.started":"2023-08-03T16:31:51.999507Z","shell.execute_reply":"2023-08-03T16:31:56.802213Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:31:56.812069Z","iopub.execute_input":"2023-08-03T16:31:56.812439Z","iopub.status.idle":"2023-08-03T16:35:47.353540Z","shell.execute_reply.started":"2023-08-03T16:31:56.812406Z","shell.execute_reply":"2023-08-03T16:35:47.352443Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666940296666629, max=1.0)…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"57b06f25fede411ba461e2b44de42908"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.8 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.5"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230803_163204-hb87rf86</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/ryanhan/huggingface/runs/hb87rf86' target=\"_blank\">dauntless-sun-8</a></strong> to <a href='https://wandb.ai/ryanhan/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/ryanhan/huggingface' target=\"_blank\">https://wandb.ai/ryanhan/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/ryanhan/huggingface/runs/hb87rf86' target=\"_blank\">https://wandb.ai/ryanhan/huggingface/runs/hb87rf86</a>"},"metadata":{}},{"name":"stderr","text":"You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [400/400 03:08, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.982282</td>\n      <td>0.530000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.828408</td>\n      <td>0.645000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=400, training_loss=0.9140534973144532, metrics={'train_runtime': 230.1563, 'train_samples_per_second': 27.807, 'train_steps_per_second': 1.738, 'total_flos': 847806470553600.0, 'train_loss': 0.9140534973144532, 'epoch': 2.0})"},"metadata":{}}]},{"cell_type":"code","source":"pred = trainer.predict(test_df).predictions\npred_ids = np.argmax(pred, 1)\ntest['spoilerType'] = pred_ids\ntest['spoilerType'] = test['spoilerType'].apply(lambda x: id2label[x])\nsubmissions = test[['id', 'spoilerType']]","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:41:32.615049Z","iopub.execute_input":"2023-08-03T16:41:32.615439Z","iopub.status.idle":"2023-08-03T16:41:36.502033Z","shell.execute_reply.started":"2023-08-03T16:41:32.615407Z","shell.execute_reply":"2023-08-03T16:41:36.501076Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"code","source":"submissions.to_csv('submissions.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T16:48:03.862532Z","iopub.execute_input":"2023-08-03T16:48:03.862926Z","iopub.status.idle":"2023-08-03T16:48:03.875788Z","shell.execute_reply.started":"2023-08-03T16:48:03.862895Z","shell.execute_reply":"2023-08-03T16:48:03.874546Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}